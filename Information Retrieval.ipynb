{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3808858",
   "metadata": {},
   "source": [
    "# Information Retrieval\n",
    "\n",
    "Firstly we have to import the required libraries such as langchain which will give us access to several models/embeddings. To convert the texts to embeddings we will use openAI's gpt-3.5-turbo model. The text data undergoes cleaning, including the merging of hyphenated words, newline characters, and other transformations, within the functions create_resume_vectorstore and create_vectorstore. After cleaning, the text is split into chunks, embeddings are generated, and ultimately, the embeddings are stored in a chroma vectorstore. The embeddings for the resumes are persisted in your local folder \"embeddings\" (which you have to create first) and the job description embeddings are stored in folder \"job_embeddings\" and can therefore be reused. Please create your own api_key on the openAI page (the used one is already expired)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba991559",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from create_vectorstore_resume import create_resume_vectorstore\n",
    "from create_job_summary import create_vectorstore, make_chain\n",
    "\n",
    "api_key = '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'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a58092b",
   "metadata": {},
   "source": [
    "To evaluate our Information Retrieval system, I utilized the Google Jobs API to extract search engine results pages (SERP) containing open job listings. For demonstration purposes, let's consider a specific job opening titled \"Research Scientist-NLP.\" As an initial step, I employed a prompt to summarize the essential technical skills sought in the job vacancy. It becomes evident that the required skills exhibit a strong correlation with NLP (Natural Language Processing) and MLOps (Machine Learning Operations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d58e005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not provided\n"
     ]
    }
   ],
   "source": [
    "open_position=\"C:/Users/SEPA/lanchain_ir2/Job_data/Research Scientist - NLP.txt\"\n",
    "\n",
    "# as your embeddings get persisted in folder job_embeddings/chroma you can reuse them later\n",
    "# please only run this one time and delete the folder job_embeddings/chroma in case you want to rerun create_vectorstore()\n",
    "chat_history = []\n",
    "chain = make_chain()\n",
    "question_job_1 = f\"Please summarise the technical skills and requirements needed for this job? Please return the answer in a concise manner, no more than 250 words. If not found, return 'Not provided'\"\n",
    "response = chain({\"question\": question_job_1, \"chat_history\": chat_history})\n",
    "required_skills = response['answer']\n",
    "print(required_skills)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a8de76",
   "metadata": {},
   "source": [
    "The path 'C:/Users/SEPA/lanchain_ir2/Resume_data_pdf/' points to a directory that contains three exmpample resumes in PDF format. The create_resume_vectorstore function is called with this path as a parameter to perform operations related to processing and organizing the resume data.\n",
    "Following that, an instance of OpenAIEmbeddings is created, which is responsible for generating embeddings for the resumes. These embeddings capture the semantic and contextual information of the CVs, allowing for more advanced analysis.\n",
    "Finally, a Chroma vectorstore is initialized with the name \"resume-embeddings\". This vectorstore utilizes the previously defined embedding function to generate the embeddings for each of the three resumes. The resulting embeddings are then stored in the specified directory for further analysis and retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6304cf23",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################### Create resume vectorstore ################\n",
    "create_resume_vectorstore('C:/Users/SEPA/lanchain_ir2/Resume_data_pdf/')\n",
    "embedding = OpenAIEmbeddings(openai_api_key=api_key)\n",
    "resume_vector_store = Chroma(\n",
    "    collection_name=\"resume-embeddings\",\n",
    "    embedding_function=embedding,\n",
    "    persist_directory=\"embeddings/chroma\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34cadd7",
   "metadata": {},
   "source": [
    "First, a retriever object is created by calling as_retriever() on the resume_vector_store instance. The parameter k is set to 3, indicating that we want to retrieve the top 3 relevant resumes.\n",
    "Next, the get_relevant_documents() method is called on the retriever object, passing the required_skills from the job description as a parameter. This retrieves a list of documents that are considered relevant based on the job vacancy.\n",
    "The similarity_search_with_score method is used, passing required_skills as the query to search for similar resumes. The distance_metric parameter is set to \"cos\" in order to use the cosine similarity metric. The k parameter is set to 3, specifying that we want to retrieve the top 3 most similar resumes along with their similarity scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a260b42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = resume_vector_store.as_retriever(search_kwargs={\"k\": 3})\n",
    "docs = retriever.get_relevant_documents(required_skills)\n",
    "\n",
    "docs_score = resume_vector_store.similarity_search_with_score(query= required_skills, distance_metric=\"cos\", k = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752afafa",
   "metadata": {},
   "source": [
    "Nowe we want to visualize and sort the results to see which applicant/resume matches best the requirements of the job vacancy. As we can see, the distance for Scheppach is the smallest, showing that our algorithms was perfectly able to capture the context of the resume and job description and detecting the NLP and MLOps related skills of the applicant Scheppach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c95f814",
   "metadata": {},
   "outputs": [],
   "source": [
    "applicant_values = []\n",
    "score_values = []\n",
    "for doc in docs_score:\n",
    "    applicant_values.append(doc[0].metadata[\"source\"].split('\\\\')[-1].split('.')[0:-1])\n",
    "    score_values.append(doc[1])\n",
    "\n",
    "data = pd.DataFrame({'Applicant': applicant_values, 'Score': score_values})\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "data.plot.bar(x='Applicant', y='Score', ax=ax)\n",
    "ax.set_xlabel('Applicants')\n",
    "ax.set_ylabel('Cosine distance')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6975b60",
   "metadata": {},
   "source": [
    "In summary: I calculated the distance between resumes and a job description, by converting the documents into their respective language embeddings. Then, I measure the similarity between the embeddings using the distance metric cosine similarity distance. The resulting distance score provides us with a quantitative measure of how closely the content of the resume aligns with the requirements outlined in the job description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305cc275",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
