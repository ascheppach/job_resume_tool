{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3808858",
   "metadata": {},
   "source": [
    "# Information Retrieval\n",
    "For this feature I will use document embeddings to calculate the cosine distance scores between resumes and job descriptions in order to be able to quantify the similarity between the skills of an applicant and the requirements for a job. The goal of this feature is to show how strongly several resumes match a job description. We will use embeddings created with the langchain library in order to  Embeddings are especially also able to detect context and not only based on keywords.\n",
    "\n",
    "Firstly we have to import the required libraries such as langchain which will give us access to embeddings. The functions create_resume_vectorstore and creaate_vectorstore will clean the text data, by removing ... Afterwards the text gets split into text chunks and finally the embeddings are stored in a chroma vectorstore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba991559",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from create_vectorstore_resume import create_resume_vectorstore\n",
    "from create_job_summary import create_vectorstore, make_chain\n",
    "\n",
    "api_key = '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'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a58092b",
   "metadata": {},
   "source": [
    "In order to test our Information Retrieval system I used the Google Jobs API to scrape SERP results from a Google Jobs search to get open jobs as example. As an example we will use an open position with the title \"Research Scientist-NLP\". As a very first step I used a prompt to summarize the required technical skills of the job vacancy.\n",
    "\n",
    "As one can see the required skills are highly related to NLP and MLOps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d58e005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ideal candidate for this job is someone who is passionate about collaborating with teammates, enjoys learning new skills, and is eager to share knowledge with others. They should have expertise in NLP, specifically in question-answering, summarization, dialog systems, reinforcement learning, or distributed systems. Prioritizing question-answering, the candidate should be familiar with dialog-based QA using APIs, program synthesis, and large knowledge-graphs/databases. A PhD in Computer Science or a related field (or a Masters with significant research experience) is preferred. The candidate should have published in top-tier ML/NLP conferences and be proficient in coding with PyTorch, Tensorflow, or JAX. Experience working with large, messy real-world data is also required.\n"
     ]
    }
   ],
   "source": [
    "################### Create job vectorstore ###################\n",
    "open_position=\"C:/Users/SEPA/lanchain_ir2/Job_data/Research Scientist - NLP.txt\"\n",
    "\n",
    "# as your embeddings get persisted in folder job_embeddings/chroma you can reuse them later\n",
    "# please only run this one time and delete the folder job_embeddings/chroma in case you want to rerun create_vectorstore()\n",
    "# create_vectorstore(open_position)\n",
    "chat_history = []\n",
    "chain = make_chain()\n",
    "question_job_1 = f\"Please summarise the technical skills and profile needed for this job? Please return the answer in a concise manner, no more than 250 words. If not found, return 'Not provided'\"\n",
    "response = chain({\"question\": question_job_1, \"chat_history\": chat_history})\n",
    "required_skills = response['answer']\n",
    "print(required_skills)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a8de76",
   "metadata": {},
   "source": [
    "The folder consists of three resumes of applicants, and using the langchain and â€¦ we will find the resume which fits best to the position based on the context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6304cf23",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################### Create resume vectorstore ################\n",
    "create_resume_vectorstore('C:/Users/SEPA/lanchain_ir2/Resume_data_pdf/')\n",
    "embedding = OpenAIEmbeddings(openai_api_key=api_key)\n",
    "resume_vector_store = Chroma(\n",
    "    collection_name=\"resume-embeddings\",\n",
    "    embedding_function=embedding,\n",
    "    persist_directory=\"embeddings/chroma\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec382289",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a260b42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = resume_vector_store.as_retriever(search_kwargs={\"k\": 3})\n",
    "# docs = retriever.get_relevant_documents(\"I have one year of experience with NLP and MLOps. Moreover I have worked with AWS, Kubernetes and Docker.\")\n",
    "docs = retriever.get_relevant_documents(required_skills)\n",
    "\n",
    "docs_score = resume_vector_store.similarity_search_with_score(query= required_skills, distance_metric=\"cos\", k = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81bba48",
   "metadata": {},
   "outputs": [],
   "source": [
    "Again the result shows that the resume of Scheppach fits best to job description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c95f814",
   "metadata": {},
   "outputs": [],
   "source": [
    "applicant_values = []\n",
    "score_values = []\n",
    "for doc in docs_score:\n",
    "    applicant_values.append(doc[0].metadata[\"source\"].split('\\\\')[-1].split('.')[0:-1])\n",
    "    score_values.append(doc[1])\n",
    "\n",
    "data = pd.DataFrame({'Applicant': applicant_values, 'Score': score_values})\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "data.plot.bar(x='Applicant', y='Score', ax=ax)\n",
    "ax.set_xlabel('Applicants')\n",
    "ax.set_ylabel('Cosine distance')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
