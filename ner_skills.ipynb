{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35690c53",
   "metadata": {},
   "source": [
    "## Named Entity Recognition\n",
    "\n",
    "In this notebook I will show how to train an Named Entity Recognition (NER) algorithm in order to be able to extract all relevant skills from an employee or applicant. In the next step I want to use the detected skill for the creation of employee and project competence profiles.\n",
    "\n",
    "The training data was genered with ChatGPT by prompting to create Jira stories in the field of Cloud, NLP and Computer Vision. The datasets were then labeled using the annotator: https://tecoholic.github.io/ner-annotator/ \n",
    "As the annotation process is very time consuming I only annotated texts for Cloud, NLP and Computer Vision. The python nlp library spacy will be used to create a custom NER model which is able to detect skill entities from texts (resumes, jira stories, project decsriptions, training courses.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6154154",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "from tqdm import tqdm\n",
    "\n",
    "nlp = spacy.blank(\"en\")  # load a new spacy model\n",
    "db = DocBin()  \n",
    "\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad3cded",
   "metadata": {},
   "source": [
    "First we will iterate over the folder labeled_entities were all the datasets are located. Each dataset gets then processed so that the data can be consumed by a spacy model and is then stored as \"./training_data_skills.spacy\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1695ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = 'C:/Users/SEPA/topic_modeling/labeled_entities'  # Replace with the path to your folder\n",
    "\n",
    "# Iterate over each file in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    f = open(folder_path + '/' + filename)\n",
    "    TRAIN_DATA = json.load(f)\n",
    "\n",
    "    for text, annot in tqdm(TRAIN_DATA['annotations']): # text ist eben text, annot sind die gelabelten annotations\n",
    "        # print(text) # text\n",
    "        # print(annot) # die annotierten entities\n",
    "        doc = nlp.make_doc(text)\n",
    "        ents = []\n",
    "        for start, end, label in annot[\"entities\"]: # ents sind einfach nur die beiden w√∂rter die er sich aus start und end zusammenbaut\n",
    "            span = doc.char_span(start, end, label=label, alignment_mode=\"contract\")\n",
    "            if span is None:\n",
    "                print(\"Skipping entity\")\n",
    "            else:\n",
    "                ents.append(span)\n",
    "        doc.ents = ents\n",
    "        db.add(doc)\n",
    "\n",
    "db.to_disk(\"./training_data_skills.spacy\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a667747",
   "metadata": {},
   "source": [
    "Run this command within a terminal to create the config file for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba99a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "! python -m spacy init config config.cfg --lang en --pipeline ner --optimize efficiency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60340461",
   "metadata": {},
   "source": [
    "Run this command within a terminal to start the model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d977b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "! python -m spacy train config.cfg --output ./ --paths.train ./training_data_skills.spacy --paths.dev ./training_data_skills.spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd842c9",
   "metadata": {},
   "source": [
    "Now we will load the best model and will use to detect the skills from a short description of my technical profile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b759171d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">I have several years of experience with \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    NLP\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
       "</mark>\n",
       " and \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    MLOps\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
       "</mark>\n",
       ". Here I implemented a \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Text Classification Algorithm\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
       "</mark>\n",
       " with \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    BERT Algorithm.\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
       "</mark>\n",
       " Moreover I have worked with \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    AWS\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Kubernetes\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
       "</mark>\n",
       " and \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Docker\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
       "</mark>\n",
       ".</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nlp_ner = spacy.load(\"C:/Users/SEPA/topic_modeling/model-best\")\n",
    "\n",
    "doc = nlp_ner('''I have several years of experience with NLP and MLOps. Here I implemented a Text Classification Algorithm with BERT Algorithm. Moreover I have worked with AWS, Kubernetes and Docker.''')\n",
    "spacy.displacy.render(doc, style=\"ent\", jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbc8201",
   "metadata": {},
   "source": [
    "As one can see, the trained NER Algorithms was able to identify all skills from a short description of my technical profile. In the next step we will store the skills from applicants to mapp applicants and employees to skillclusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ee3a55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
